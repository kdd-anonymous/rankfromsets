import bottleneck as bn
import numpy as np
import bottleneck as bn
#import mxnet as mx
import logging
from tqdm import tqdm


def precision_recall_at_k(pred, true_idx, k=5):
  """Precision and recall at k."""
  # top k items are recommended
  idx = bn.argpartition(-pred, k)
  pred_binary = np.zeros_like(pred, dtype=bool)
  pred_binary[idx[:k]] = True
  true_binary = np.zeros_like(pred, dtype=bool)
  true_binary[true_idx] = True
  true_positives = np.logical_and(true_binary, pred_binary).sum().astype(np.float32)
  # precision = true positives / true positives + false positives.
  # for precision@k we make k predictions, so the denominator is simply k.
  precision = true_positives / k
  # recall = true positives / true positives + false negatives
  # false negatives: incorrectly predict negative label
  recall = true_positives / np.minimum(k, len(true_idx))
  return precision, recall

# def precision_recall_at_k_batch(pred, true_idx_list, k):
#   """Precision and recall at k for a batch of predictions."""
#   # top k items are recommended
#   idx = bn.argpartition(-pred, k, axis=1)
#   pred_binary = np.zeros_like(pred, dtype=bool)
#   pred_binary[np.arange(len(pred))[:, np.newaxis], idx[:, :k]] = True
#   true_binary = np.zeros_like(pred, dtype=bool)
#   for i, true_idx in enumerate(true_idx_list):
#     true_binary[i, true_idx] = True
#   true_positives = np.logical_and(true_binary, pred_binary).sum(axis=1).astype(np.float32)
#   # precision = true positives / true positives + false positives.
#   # for precision@k we make k predictions, so the denominator is simply k.
#   precision = true_positives / k
#   # recall = true positives / true positives + false negatives
#   # false negatives: incorrectly predict negative label
#   recall = true_positives / np.minimum(k, true_binary.sum(axis=1))
#   return precision, recall


def recall_at_k(pred, true_idx, k=5):
  """Recall at k. Assumes top k predictions in pred are positive."""
  idx = np.argsort(pred)[::-1]
  true_positives = set(idx[:k]).intersection(true_idx)
  recall = len(true_positives) / min(k, len(true_idx))
  return recall


def compute_user_recall_list(pred):
  """Calculate recall for user, assumes every 10th meal_emb is true.

  pred is a list of predictions from a model.
  """
  pred = np.squeeze(pred)
  n_pred = pred.shape[0]
  correct_meals = list(range(0, n_pred, 10))
  n_user_meals = n_pred / 10
  zero = np.array([0], dtype=int)
  pred_split = np.split(pred, n_user_meals)
  user_recall = []
  for single_meal_pred in pred_split:
    meal_recall = []
    for k in range(1, 11):
      meal_prec.append(precision_at_k(single_meal_pred, true_idx=zero, k=k))
    user_prec.append(meal_prec)
  precision_lists = zip(*user_prec)
  return [np.mean(prec_list) for prec_list in precision_lists]


def recall_at_k(pred, true_idx, k=5):
  """Recall at k. Assumes top k predictions in pred are positive."""
  idx = np.argsort(pred)[::-1]
  true_positives = set(idx[:k]).intersection(true_idx)
  recall = len(true_positives) / min(k, len(true_idx))
  return recall

def compute_user_recall_list(pred):
  """Calculate recall for user, assumes every 10th meal_emb is true.
  pred is a list of predictions from a model.
  """
  pred = np.squeeze(pred)
  n_pred = pred.shape[0]
  correct_meals = list(range(0, n_pred, 10))
  n_user_meals = n_pred / 10
  zero = np.array([0], dtype=int)
  pred_split = np.split(pred, n_user_meals)
  user_recall = []
  for single_meal_pred in pred_split:
    meal_recall = []
    for k in range(1, 11):
      meal_recall.append(recall_at_k(single_meal_pred, true_idx=zero, k=k))
    user_recall.append(meal_recall)
  recall_lists = zip(*user_recall)
  return [np.mean(recall_list) for recall_list in recall_lists]

def eval_crowdsourced_set_data(model, heldout_data, heldout_name):
  """Calculate recall/recall@1."""
  res = []
  logger = logging.getLogger(__name__)
  context = mx.current_context()
  for batch in tqdm(heldout_data, heldout_name):
    batch = (x.as_in_context(context) for x in batch)
    users, items, item_counts, set_sizes, bias_idx, bias_sizes = batch
    pred = model(users, items, item_counts, set_sizes, bias_idx, bias_sizes)
    res.append(compute_user_recall_list(pred.asnumpy()))
  recall_lists = zip(*res)
  recall_lists = [np.mean(lst) for lst in recall_lists]
  for i, recall in enumerate(recall_lists):
    logger.info('\t%s: mean recall at k=%d: %.2f\trandom: %.2f' %
                 (heldout_name, i + 1, recall, (i + 1) / 10.))
  return recall_lists


def precision_recall_at_k_batch(pred, idx, true_idx_list, k):
  """Precision and recall at k for a batch of predictions."""
  # top k items are recommended
  pred_binary = np.zeros_like(pred, dtype=bool)
  pred_binary[np.arange(len(pred))[:, np.newaxis], idx[:, :k]] = True
  true_binary = np.zeros_like(pred, dtype=bool)
  for i, true_idx in enumerate(true_idx_list):
    true_binary[i, true_idx] = True
  true_positives = np.logical_and(true_binary, pred_binary).sum(axis=1).astype(np.float32)
  # precision = true positives / true positives + false positives.
  # for precision@k we make k predictions, so the denominator is simply k.
  precision = true_positives / k
  # recall = true positives / true positives + false negatives
  recall = true_positives / true_binary.sum(axis=1)
  return precision, recall

def user_idx_generator(users, batch_size):
  """helper function to generate the user index to loop through the dataset"""
  n_users = len(users)
  for start in range(0, n_users, batch_size):
    end = min(n_users, start + batch_size)
    yield users[start:end]
